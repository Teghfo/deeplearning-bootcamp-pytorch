{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "w6YucXZRMHoK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
        "!unzip -q spa-eng.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8IpkiI6Mbpn",
        "outputId": "1170683d-7fd3-4bc3-fa39-b9dcdb26d9ce"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-12 08:26:58--  http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.117.207, 142.250.99.207, 74.125.20.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.117.207|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2638744 (2.5M) [application/zip]\n",
            "Saving to: ‘spa-eng.zip.1’\n",
            "\n",
            "\rspa-eng.zip.1         0%[                    ]       0  --.-KB/s               \rspa-eng.zip.1       100%[===================>]   2.52M  --.-KB/s    in 0.008s  \n",
            "\n",
            "2024-04-12 08:26:58 (309 MB/s) - ‘spa-eng.zip.1’ saved [2638744/2638744]\n",
            "\n",
            "replace spa-eng/_about.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace spa-eng/spa.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VZOyujZLa-x5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_file = \"spa-eng/spa.txt\"\n",
        "with open(text_file) as f:\n",
        "  lines = f.read().split(\"\\n\")[:-1]\n",
        "\n",
        "data = []\n",
        "source_data = []\n",
        "target_data = []\n",
        "for line in lines:\n",
        "  source, target = line.split('\\t')\n",
        "  source_data.append(source)\n",
        "  target_data.append(target)\n",
        "  data.append((source, target))"
      ],
      "metadata": {
        "id": "2nb5r67nMmQI"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YoHBkt2PM8u",
        "outputId": "00315234-dc0f-44b9-f996-117e9a7af826"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo.',\n",
              " 'Si quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un músico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado.')"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random.shuffle(data)\n",
        "num_val_samples = int(0.15 * len(data))\n",
        "num_train_samples = len(data) - 2 * num_val_samples\n",
        "\n",
        "train_pairs = data[:num_train_samples]\n",
        "val_pairs = data[num_train_samples:num_train_samples + num_val_samples]\n",
        "test_pairs = data[num_train_samples + num_val_samples:]"
      ],
      "metadata": {
        "id": "rJLnVibfPVEz"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import string\n",
        "from tqdm import tqdm\n",
        "\n",
        "strip_chars = string.punctuation + \"¿\"\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "\n",
        "class TextVectorizer:\n",
        "\n",
        "  def __init__(self, sequence_length, vocab_size, target=False):\n",
        "    self.target = target\n",
        "    self.sequence_length = sequence_length\n",
        "    self.vocab_size = vocab_size\n",
        "    self.vocab_counter = Counter()\n",
        "    self.stoi = {\"[pad]\": 0, \"[start]\": 1, \"[end]\": 2, \"[UNK]\": 3}\n",
        "    self.itos = {0: \"[pad]\", 1: \"[start]\", 2: \"[end]\", 3: \"[UNK]\"}\n",
        "\n",
        "  def standardize(self, text):\n",
        "    text = text.lower()\n",
        "    return \"\".join(char for char in text\n",
        "                  if char not in strip_chars)\n",
        "\n",
        "  def tokenize(self, text):\n",
        "    text = self.standardize(text)\n",
        "    return text.split()\n",
        "\n",
        "  def adapt(self, dataset):\n",
        "\n",
        "    for text in tqdm(dataset):\n",
        "      tokens = self.tokenize(text)\n",
        "      for token in tokens:\n",
        "        self.vocab_counter[token] += 1\n",
        "\n",
        "    for token, _ in self.vocab_counter.most_common(self.vocab_size):\n",
        "      indx = len(self.stoi)\n",
        "      self.stoi[token] = indx\n",
        "      self.itos[indx] = token\n",
        "\n",
        "  def encode(self, text):\n",
        "    text = self.standardize(text)\n",
        "    tokens = self.tokenize(text)\n",
        "    if self.target:\n",
        "      result = ([self.stoi[\"[start]\"]] + [self.stoi.get(token, 3) for token in tokens]\n",
        "            + [self.stoi[\"[end]\"]])\n",
        "    else:\n",
        "      result = [self.stoi.get(token, 3) for token in tokens]\n",
        "\n",
        "    if len(result) <= self.sequence_length:\n",
        "        pad_size = self.sequence_length - len(result)\n",
        "        result += [self.stoi.get(\"[pad]\")] * (pad_size)\n",
        "    else:\n",
        "      #truncate!\n",
        "      result = result[:self.sequence_length]\n",
        "\n",
        "    return result\n",
        "\n",
        "  def decode(self, int_sequence):\n",
        "    return \" \".join(self.itos.get(i, \"[UNK]\") for i in int_sequence)"
      ],
      "metadata": {
        "id": "3P3Je3FeQdgE"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "\n",
        "source_vectorizer = TextVectorizer(sequence_length, vocab_size)\n",
        "target_vectorizer = TextVectorizer(sequence_length + 1, vocab_size, target=True)"
      ],
      "metadata": {
        "id": "rYJcjnLfUFTP"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_vectorizer.adapt(source_data)\n",
        "target_vectorizer.adapt(target_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIiFXjacgsIE",
        "outputId": "f2c8ccc3-3eea-4a06-b5d3-1a904a8de291"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118964/118964 [00:00<00:00, 172544.06it/s]\n",
            "100%|██████████| 118964/118964 [00:00<00:00, 150749.81it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_ = source_vectorizer.encode('If you want to sound')\n",
        "source_vectorizer.decode(encoded_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MsmUNp4niGjR",
        "outputId": "ea0f1bf1-b7fc-4fca-a7ff-6ddeddc3a994"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'if you want to sound [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eng, spa = train_pairs[1]\n",
        "source_vectorizer.encode(eng)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5FVsY8TuB-Q",
        "outputId": "84c4887b-4f74-46e3-9604-8a0667436403"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[11, 10, 249, 5843, 4, 3776, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EngSpaDataset(Dataset):\n",
        "  def __init__(self, data, source_vectorizer, target_vectorizer):\n",
        "    self.data = data\n",
        "    self.source_vectorizer = source_vectorizer\n",
        "    self.target_vectorizer = target_vectorizer\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    eng, spa = self.data[idx]\n",
        "    eng = self.source_vectorizer.encode(eng)\n",
        "    spa = self.target_vectorizer.encode(spa)\n",
        "    return ({\n",
        "          \"english\": torch.tensor(eng).long(),\n",
        "          \"spanish\": torch.tensor(spa[:-1]).long(),\n",
        "          }, torch.tensor(spa[1:]).long())"
      ],
      "metadata": {
        "id": "z8vv0B9WqgTa"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = EngSpaDataset(train_pairs, source_vectorizer, target_vectorizer)\n",
        "val_ds = EngSpaDataset(val_pairs, source_vectorizer, target_vectorizer)\n",
        "test_ds = EngSpaDataset(test_pairs, source_vectorizer, target_vectorizer)"
      ],
      "metadata": {
        "id": "P8nRx0NXsq5L"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def permute_batch_seq_collate(data: torch.Tensor):\n",
        "  batch_size = len(data)\n",
        "  source_input = torch.zeros(batch_size, data[0][0][\"english\"].size(0))\n",
        "  target_input = torch.zeros(batch_size, data[0][0][\"spanish\"].size(0))\n",
        "  target_output = torch.zeros(batch_size, data[0][1].size(0))\n",
        "  for idx, (inputs, output) in enumerate(data):\n",
        "    source_input[idx] = inputs[\"english\"]\n",
        "    target_input[idx] = inputs[\"spanish\"]\n",
        "    target_output[idx] = output\n",
        "\n",
        "  return (source_input.permute(1, 0).long(), target_input.permute(1, 0).long(),\n",
        "          target_output.permute(1, 0).long())"
      ],
      "metadata": {
        "id": "247rD58eYFPK"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
        "                      collate_fn=permute_batch_seq_collate)\n",
        "val_dl = DataLoader(val_ds, batch_size=batch_size,\n",
        "                    collate_fn=permute_batch_seq_collate)\n",
        "test_dl = DataLoader(test_ds, batch_size=batch_size,\n",
        "                     collate_fn=permute_batch_seq_collate)"
      ],
      "metadata": {
        "id": "d512sQbstCm5"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for source, target_inp, target_out in train_dl:\n",
        "  print(source)\n",
        "  print(\"source tensor size: \", source.size())\n",
        "  print(\"target input tensor size: \", target_inp.size())\n",
        "  print(\"target tensor size: \", target_out.size())\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeyoIjW6tmBt",
        "outputId": "975be692-31ba-49c0-b1a0-5065238fb4da"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[   5,    8,   23,  ...,    8,   26,    8],\n",
            "        [ 305,  207,   61,  ...,  203, 4677,   10],\n",
            "        [   5,   27,  468,  ...,    6,   75,  841],\n",
            "        ...,\n",
            "        [   0,    0,    0,  ...,    0,    0,    0],\n",
            "        [   0,    0,    0,  ...,    0,    0,    0],\n",
            "        [   0,    0,    0,  ...,    0,    0,    0]])\n",
            "source tensor size:  torch.Size([20, 64])\n",
            "target input tensor size:  torch.Size([20, 64])\n",
            "target tensor size:  torch.Size([20, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, source_dim : int, embedding_dim : int, hidden_dim : int,\n",
        "               padding_idx : int=0, num_rnn_layers: int=1, dropout: int = 0.2):\n",
        "    super().__init__()\n",
        "    self.source_dim = source_dim\n",
        "    self.embedding_dim =  embedding_dim\n",
        "    self.hidden_dim =  hidden_dim\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    self.embedding_layer = nn.Embedding(self.source_dim, self.embedding_dim,\n",
        "                                        padding_idx=padding_idx)\n",
        "    self.lstm = nn.LSTM(self.embedding_dim, self.hidden_dim,\n",
        "                        num_layers=num_rnn_layers)\n",
        "\n",
        "  def forward(self, x : torch.Tensor):\n",
        "    x = self.embedding_layer(x)\n",
        "    x = self.dropout(x)\n",
        "    output, (hidden_state, cell_state) = self.lstm(x)\n",
        "    return hidden_state, cell_state\n",
        "\n",
        "# vocab_size = len(source_vectorizer.stoi)\n",
        "# print(\"vocab_size\", vocab_size)\n",
        "# x = torch.randint(0, vocab_size, size = (20, 64))\n",
        "# encoder = Encoder(vocab_size, 256, 300)\n",
        "# encoder(x)[0].size()"
      ],
      "metadata": {
        "id": "3Cz2Ysm9u-tQ"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, target_dim : int, embedding_dim : int, hidden_dim : int,\n",
        "               padding_idx : int=0, num_rnn_layers: int=1, dropout: int = 0.2):\n",
        "    super().__init__()\n",
        "    self.target_dim = target_dim\n",
        "    self.embedding_dim =  embedding_dim\n",
        "    self.hidden_dim =  hidden_dim\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    self.embedding_layer = nn.Embedding(self.target_dim, self.embedding_dim,\n",
        "                                        padding_idx=padding_idx)\n",
        "    self.lstm = nn.LSTM(self.embedding_dim, self.hidden_dim,\n",
        "                        num_layers=num_rnn_layers)\n",
        "    self.classifier = nn.Linear(hidden_dim, target_dim)\n",
        "\n",
        "  def forward(self, x, hidden_state, cell_state):\n",
        "    x = self.embedding_layer(x)\n",
        "    x = self.dropout(x)\n",
        "    outputs, (hidden_state, cell_state) = self.lstm(x, (hidden_state, cell_state))\n",
        "    predictions = self.classifier(outputs)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# vocab_size = len(target_vectorizer.stoi)\n",
        "# print(\"vocab_size\", vocab_size)\n",
        "# x = torch.randint(0, vocab_size, size = (20, 64))\n",
        "# h, c = torch.randn(1, 64, 300), torch.randn(1, 64, 300)\n",
        "# decoder = Decoder(vocab_size, 256, 300)\n",
        "# decoder(x, h, c).size()"
      ],
      "metadata": {
        "id": "2VdxiF7PTM7J"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NMTNet(nn.Module):\n",
        "  def __init__(self, encoder, decoder):\n",
        "    super().__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def forward(self, source, target):\n",
        "    encoder_output = self.encoder(source)\n",
        "    output = self.decoder(target, *encoder_output)\n",
        "    return output\n",
        "\n",
        "source_vocab_size = len(source_vectorizer.stoi)\n",
        "target_vocab_size = len(target_vectorizer.stoi)\n",
        "print(\"source_vocab_size\", source_vocab_size)\n",
        "print(\"target_vocab_size\", target_vocab_size)\n",
        "source = torch.randint(0, source_vocab_size, size = (20, 64))\n",
        "target = torch.randint(0, target_vocab_size, size = (20, 64))\n",
        "encoder = Encoder(source_vocab_size, 256, 300)\n",
        "decoder = Decoder(target_vocab_size, 256, 300)\n",
        "model = NMTNet(encoder, decoder)\n",
        "model(source, target).size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRi3cCv5dq9P",
        "outputId": "a4514615-a107-495e-9723-4048ab5d6bc3"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source_vocab_size 13636\n",
            "target_vocab_size 15004\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 64, 15004])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn.LSTM(12, 10)"
      ],
      "metadata": {
        "id": "14CiCRqig8cP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model hyperparameters\n",
        "source_vocab_size = len(source_vectorizer.stoi)\n",
        "target_vocab_size = len(target_vectorizer.stoi)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "hidden_dim = 512\n",
        "encoder_embedding_dim = 128\n",
        "decoder_embedding_dim = 128\n",
        "padding_index = target_vectorizer.stoi[\"[pad]\"]\n",
        "\n",
        "learning_rate = 0.001\n",
        "num_epochs = 20\n",
        "\n",
        "\n",
        "encoder = Encoder(\n",
        "    source_vocab_size,\n",
        "    encoder_embedding_dim,\n",
        "    hidden_dim\n",
        "    ).to(device)\n",
        "\n",
        "decoder = Decoder(\n",
        "    target_vocab_size,\n",
        "    decoder_embedding_dim,\n",
        "    hidden_dim\n",
        "    ).to(device)\n",
        "\n",
        "model = NMTNet(\n",
        "    encoder,\n",
        "    decoder\n",
        "    ).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=padding_index)\n",
        "optimizer = torch.optim.NAdam(model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "F3IHygQ7fMEe"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(12, 3, 32)\n",
        "x.reshape(-1, 32).size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56UTF5YjnqlV",
        "outputId": "3222f2ec-a264-4334-a77b-24b179e18b9e"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([36, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.tensor(2) == torch.tensor(2):\n",
        "  print(\"SALAM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6SXmp9sZOrT",
        "outputId": "c288d32d-c4bf-41f0-ce81-db3a2be7f615"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SALAM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cal_accuracy(source, target):\n",
        "  predictions = source.argmax(1)\n",
        "  correct = 0\n",
        "  for idx, token in enumerate(predictions):\n",
        "    text = target_vectorizer.itos[token.item()]\n",
        "    if target[idx] == token:\n",
        "      correct += 1\n",
        "    if text == \"[end]\":\n",
        "      break\n",
        "  return correct / (idx+1)"
      ],
      "metadata": {
        "id": "Ea-AbbqsH0Y5"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  model.train()\n",
        "  train_loss = 0.0\n",
        "  val_loss = 0.0\n",
        "  train_acc = 0.0\n",
        "  val_acc = 0.0\n",
        "\n",
        "  for idx, (source, target_inp, target_out) in enumerate(tqdm(train_dl)):\n",
        "    source = source.to(device)\n",
        "    target_inp = target_inp.to(device)\n",
        "    target_out = target_out.to(device)\n",
        "\n",
        "    predictions = model(source, target_inp)\n",
        "    # seq_length * batch\n",
        "    loss = criterion(predictions.reshape(-1, predictions.shape[2]), target_out.reshape(-1))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss.item()\n",
        "    with torch.no_grad():\n",
        "      train_acc += cal_accuracy(predictions.reshape(-1, predictions.shape[2]), target_out.reshape(-1))\n",
        "\n",
        "    # if idx % 500 == 0:\n",
        "    #   print(f\"Epoch{epoch+1}/{num_epochs} step {idx+1} | \\\n",
        "    #               train_loss: {train_loss / (idx+1)} | train_acc {train_acc / (idx+1)}\")\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for idx, (source, target_inp, target_out) in enumerate((val_dl)):\n",
        "      source = source.to(device)\n",
        "      target_inp = target_inp.to(device)\n",
        "      target_out = target_out.to(device)\n",
        "\n",
        "      predictions = model(source, target_inp)\n",
        "      # seq_length * batch\n",
        "      loss = criterion(predictions.reshape(-1, predictions.shape[2]), target_out.reshape(-1))\n",
        "\n",
        "      val_loss += loss.item()\n",
        "      val_acc += cal_accuracy(predictions.reshape(-1, predictions.shape[2]), target_out.reshape(-1))\n",
        "\n",
        "  print(f\"\\n Epoch{epoch+1}/{num_epochs} | \\\n",
        "          train_loss: {train_loss / len(train_dl)}| train_acc {train_acc / len(train_dl)} \\\n",
        "           | val_loss: {val_loss / len(val_dl)} | val_acc {val_acc / len(val_dl)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-hUsJhuiL49",
        "outputId": "a5cdf8cd-b516-4c86-d57a-211f01815550"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1302/1302 [00:48<00:00, 26.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch1/20 |           train_loss: 4.475375846783686| train_acc 0.3254478127483873            | val_loss: 3.4453619346823743 | val_acc 0.48056486591941605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1302/1302 [00:49<00:00, 26.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch2/20 |           train_loss: 2.9149965362797867| train_acc 0.5155839568795977            | val_loss: 2.6993112068449725 | val_acc 0.5585776918759865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1302/1302 [00:49<00:00, 26.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch3/20 |           train_loss: 2.206947722834193| train_acc 0.577698804786036            | val_loss: 2.3888655366863403 | val_acc 0.5929203062515481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1302/1302 [00:50<00:00, 25.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch4/20 |           train_loss: 1.7647765539758216| train_acc 0.6226053515431009            | val_loss: 2.246700680811345 | val_acc 0.6090100019450841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1302/1302 [00:50<00:00, 25.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch5/20 |           train_loss: 1.4707486049920184| train_acc 0.6607976704068343            | val_loss: 2.1809156898102025 | val_acc 0.6221130918366956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1302/1302 [00:50<00:00, 25.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch6/20 |           train_loss: 1.2603264001016425| train_acc 0.6904105985316764            | val_loss: 2.1631913706393227 | val_acc 0.6230686125064631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1302/1302 [00:50<00:00, 25.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch7/20 |           train_loss: 1.1115955782284568| train_acc 0.7116710874841048            | val_loss: 2.1467980428408553 | val_acc 0.6320457105486332\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1302/1302 [00:51<00:00, 25.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch8/20 |           train_loss: 0.9954095465887893| train_acc 0.7309588313772689            | val_loss: 2.1536935033764038 | val_acc 0.6347677640556496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1302/1302 [00:51<00:00, 25.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch9/20 |           train_loss: 0.9069521975132727| train_acc 0.7461852787089038            | val_loss: 2.1772274983826505 | val_acc 0.6392055948895343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1302/1302 [00:51<00:00, 25.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch10/20 |           train_loss: 0.8337412425266799| train_acc 0.7591472104877967            | val_loss: 2.1978165723089678 | val_acc 0.6368526761286892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1302/1302 [00:51<00:00, 25.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch11/20 |           train_loss: 0.7730866520452426| train_acc 0.7719352944383923            | val_loss: 2.218692331331178 | val_acc 0.6426024190698066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1302/1302 [00:51<00:00, 25.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch12/20 |           train_loss: 0.7220242944089682| train_acc 0.7814706935142135            | val_loss: 2.2507016060600145 | val_acc 0.6403277436949546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1302/1302 [00:50<00:00, 25.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch13/20 |           train_loss: 0.6793933025519786| train_acc 0.7903385124214117            | val_loss: 2.28068047185098 | val_acc 0.6406670713061889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1302/1302 [00:51<00:00, 25.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch14/20 |           train_loss: 0.6411904086074155| train_acc 0.7979402966519744            | val_loss: 2.3143176442833355 | val_acc 0.6403923977869014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1302/1302 [00:50<00:00, 25.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch15/20 |           train_loss: 0.6105503520474822| train_acc 0.8049781496163247            | val_loss: 2.3355849596761886 | val_acc 0.6421134442736047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1302/1302 [00:50<00:00, 25.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch16/20 |           train_loss: 0.5825207333914512| train_acc 0.8106307146824847            | val_loss: 2.3653518974140124 | val_acc 0.6396632323385345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1302/1302 [00:50<00:00, 25.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch17/20 |           train_loss: 0.5543347009544914| train_acc 0.8172604529117572            | val_loss: 2.401506536750383 | val_acc 0.6420390049933009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1302/1302 [00:50<00:00, 25.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch18/20 |           train_loss: 0.530749029850447| train_acc 0.8236021049772841            | val_loss: 2.431323788072046 | val_acc 0.6407041564606353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1302/1302 [00:50<00:00, 25.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch19/20 |           train_loss: 0.5108629057095164| train_acc 0.8269811250653376            | val_loss: 2.4456300346654802 | val_acc 0.6412336706066967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1302/1302 [00:50<00:00, 25.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch20/20 |           train_loss: 0.49367910655595926| train_acc 0.832519700144898            | val_loss: 2.481045982743677 | val_acc 0.6401899285437315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "source, target_inp, target_out = next(iter(val_dl))\n",
        "prediction = model(source.to(device), target_inp.to(device))\n",
        "# target_vectorizer\n",
        "prediction[:, 0].argmax(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWiCXWClUXed",
        "outputId": "690145fd-90fb-47e5-9450-afec12e798aa"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 18,  14, 885,  40,  40,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
              "          2,   2,   2,   2,   2,   2], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translate = \"\"\n",
        "for i in prediction[:, 18].argmax(1):\n",
        " text = target_vectorizer.itos[i.item()]\n",
        " translate += \" \" + text\n",
        " if text == \"[end]\":\n",
        "  break\n",
        "translate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IgxxqnnCVKwZ",
        "outputId": "ad4f72e3-5d28-42ee-dcd5-d1f2a6595739"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' el lugar está completamente desierto [end]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translate = \"\"\n",
        "for i in target_out[:, 18]:\n",
        " text = target_vectorizer.itos[i.item()]\n",
        " translate += \" \" + text\n",
        " if text == \"[end]\":\n",
        "  break\n",
        "translate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8nAyU3p1WMdl",
        "outputId": "2f2f5c47-2249-4502-895a-9c8909ef428e"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' el lugar está completamente desierto [end]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    }
  ]
}