{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "-zQlF_Ejqgqg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ILITYdzLQziv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b7c3f45-4ffb-4b8a-b7ef-b3132a547064"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG_DIR = \"/content/drive/MyDrive/datasets/yoloData/\""
      ],
      "metadata": {
        "id": "iAXCS1g5u_G2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/drive/MyDrive/datasets/yoloData/yolov3.cfg\n"
      ],
      "metadata": {
        "id": "pzR8MKd92llH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def clean_data(lines_):\n",
        "  result = []\n",
        "  for line in lines_:\n",
        "    if len(line) > 0 and line[0] != \"#\":\n",
        "      result.append(line.strip())\n",
        "  return result\n",
        "\n",
        "def parse_config_file(config_file):\n",
        "  with open(config_file, \"r\") as f:\n",
        "    lines_data = f.read()\n",
        "    lines = lines_data.split(\"\\n\")\n",
        "    lines = clean_data(lines)\n",
        "\n",
        "  result = []\n",
        "  block = {}\n",
        "\n",
        "  for line in lines:\n",
        "    if line[0] == \"[\":\n",
        "      if \"block_name\" in block:\n",
        "        result.append(block)\n",
        "        block = {}\n",
        "      block_name = line[1:-1]\n",
        "      block[\"block_name\"] = block_name\n",
        "\n",
        "    else:\n",
        "      key, val = line.split(\"=\")\n",
        "      block[key.strip()] = val.strip()\n",
        "\n",
        "  result.append(block)\n",
        "  return result\n",
        "\n",
        "\n",
        "config = parse_config_file(os.path.join(CONFIG_DIR, \"yolov3.cfg\"))\n",
        "config[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0JIOxdpA75_",
        "outputId": "112c57e4-e19a-41de-b493-fefb8ed1d5aa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'block_name': 'net',\n",
              " 'batch': '1',\n",
              " 'subdivisions': '1',\n",
              " 'width': '416',\n",
              " 'height': '416',\n",
              " 'channels': '3',\n",
              " 'momentum': '0.9',\n",
              " 'decay': '0.0005',\n",
              " 'angle': '0',\n",
              " 'saturation': '1.5',\n",
              " 'exposure': '1.5',\n",
              " 'hue': '.1',\n",
              " 'learning_rate': '0.001',\n",
              " 'burn_in': '1000',\n",
              " 'max_batches': '500200',\n",
              " 'policy': 'steps',\n",
              " 'steps': '400000,450000',\n",
              " 'scales': '.1,.1'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c_y, c_x = torch.meshgrid(torch.arange(13), torch.arange(13), indexing=\"ij\")\n",
        "c_x, c_y = c_x.reshape(-1, 1), c_y.reshape(-1, 1)\n",
        "torch.cat((c_x, c_y), 1).repeat(1, 3).view(-1, 2).unsqueeze(0)[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6MBN6y4G_x3",
        "outputId": "6bad8678-c4b5-4e79-bbf5-3e2b01ccee2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0,  0],\n",
              "         [ 0,  0],\n",
              "         [ 0,  0],\n",
              "         ...,\n",
              "         [12, 12],\n",
              "         [12, 12],\n",
              "         [12, 12]]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict, Tuple\n",
        "\n",
        "\n",
        "class ShortCut(nn.Module):\n",
        "  def __init__(self, from_):\n",
        "    super().__init__()\n",
        "    self.from_ = int(from_)\n",
        "\n",
        "\n",
        "class Route(nn.Module):\n",
        "  def __init__(self, start, end=None):\n",
        "    super().__init__()\n",
        "    self.start = int(start)\n",
        "    if end:\n",
        "      self.end = int(end)\n",
        "    else:\n",
        "      self.end = end\n",
        "\n",
        "\n",
        "class DetectionModule(nn.Module):\n",
        "  def __init__(self, anchors: List[Tuple[int]], classes: int,\n",
        "               ignore_thresh: int):\n",
        "    super().__init__()\n",
        "    self.anchors = anchors\n",
        "    self.classes = int(classes)\n",
        "    self.ignore_thresh = ignore_thresh\n",
        "\n",
        "\n",
        "class YoloV3Net(nn.Module):\n",
        "\n",
        "  def __init__(self, config_: List[Dict[str, str]], device=\"cpu\") -> None:\n",
        "    super().__init__()\n",
        "    self.config = config_\n",
        "    self.device = device\n",
        "    self.net_config = self.config[0]\n",
        "    self.modules_ = self.create_arc()\n",
        "\n",
        "  def create_arc(self):\n",
        "    modules = nn.ModuleList()\n",
        "    prev_channels = int(self.net_config[\"channels\"])\n",
        "    layer_out_channel_size = []\n",
        "\n",
        "    for i, block in enumerate(self.config[1:]):\n",
        "      module = nn.Sequential()\n",
        "\n",
        "      match block[\"block_name\"]:\n",
        "\n",
        "        case \"convolutional\":\n",
        "\n",
        "          out_channels, kernel_size, stride, padding, activation = \\\n",
        "          int(block[\"filters\"]), int(block[\"size\"]), int(block[\"stride\"]), \\\n",
        "          int(block[\"pad\"]), block[\"activation\"]\n",
        "\n",
        "          padding = 0 if not padding else (kernel_size - 1) // 2\n",
        "\n",
        "          if block.get(\"batch_normalize\", 0):\n",
        "            conv = nn.Conv2d(prev_channels, out_channels, kernel_size= kernel_size,\n",
        "                           stride=stride, padding=padding, bias=False)\n",
        "            module.add_module(f\"conv_{i}\", conv)\n",
        "            module.add_module(f\"bn_{i}\", nn.BatchNorm2d(out_channels))\n",
        "            module.add_module(f\"activation_leaky_{i}\", nn.LeakyReLU())\n",
        "          else:\n",
        "            conv = nn.Conv2d(prev_channels, out_channels, kernel_size= kernel_size,\n",
        "                           stride=stride, padding=padding, bias=True)\n",
        "            module.add_module(f\"conv_{i}\", conv)\n",
        "\n",
        "\n",
        "        case \"shortcut\":\n",
        "          module.add_module(f\"shortcut_{i}\", ShortCut(block[\"from\"]))\n",
        "\n",
        "        case \"upsample\":\n",
        "          module.add_module(f\"upsample_{i}\",\n",
        "                            nn.Upsample(scale_factor = int(block[\"stride\"])))\n",
        "\n",
        "\n",
        "        case \"route\":\n",
        "          num_route = block[\"layers\"].split(\",\")\n",
        "          if len(num_route) == 1:\n",
        "            start = int(block[\"layers\"])\n",
        "            if start > 0:\n",
        "              start = start - i\n",
        "            out_channels = layer_out_channel_size[i + start]\n",
        "            module.add_module(f\"route_{i}\",\n",
        "                            Route(start))\n",
        "          else:\n",
        "            start, end = block[\"layers\"].split(\",\")\n",
        "            start = int(start.strip())\n",
        "            end = int(end.strip())\n",
        "            if start > 0:\n",
        "              start = start - i\n",
        "            if end > 0:\n",
        "              end = end - i\n",
        "            out_channels = layer_out_channel_size[i + start] + \\\n",
        "                                  layer_out_channel_size[i + end]\n",
        "            module.add_module(f\"route_{i}\",\n",
        "                            Route(start, end))\n",
        "\n",
        "        case \"yolo\":\n",
        "          mask = [int(i) for i in block[\"mask\"].split(\",\")]\n",
        "          all_anchors = [int(i) for i in block[\"anchors\"].split(\",\")]\n",
        "          packed_anchors = [(all_anchors[i], all_anchors[i+1]) for i in\n",
        "                            range(0, len(all_anchors), 2)]\n",
        "          anchors = [packed_anchors[i] for i in mask]\n",
        "          anchors = torch.tensor(anchors).float().to(self.device)\n",
        "          classes, ignore_thresh = block[\"classes\"], block[\"ignore_thresh\"]\n",
        "          module.add_module(f\"detection_{i}\",\n",
        "                            DetectionModule(anchors, classes, ignore_thresh))\n",
        "\n",
        "\n",
        "      modules.append(module)\n",
        "      prev_channels = out_channels\n",
        "      layer_out_channel_size.append(out_channels)\n",
        "    return modules\n",
        "\n",
        "  def forward(self, x):\n",
        "    cache_output = {}\n",
        "    count_predictor = 0\n",
        "    for i, block in enumerate(self.config[1:]):\n",
        "      match block[\"block_name\"]:\n",
        "\n",
        "        case \"convolutional\":\n",
        "          x = self.modules_[i](x)\n",
        "\n",
        "        case \"shortcut\":\n",
        "          from_ = int(self.modules_[i][0].from_)\n",
        "          x = cache_output[i-1] + cache_output[i + from_]\n",
        "\n",
        "        case \"route\":\n",
        "          start = int(self.modules_[i][0].start)\n",
        "          end = self.modules_[i][0].end\n",
        "          if end:\n",
        "            x = torch.cat((cache_output[i + start], cache_output[i + end]), 1)\n",
        "          else:\n",
        "            x = cache_output[i + start]\n",
        "\n",
        "        case \"upsample\":\n",
        "          x = self.modules_[i](x)\n",
        "\n",
        "        case \"yolo\":\n",
        "          # batch * 255 * 13 * 13 ===> [x, y, w , h, os, ...]\n",
        "          x = self.predict_detection(x, self.modules_[i][0].classes, self.modules_[i][0].anchors)\n",
        "          if count_predictor == 0:\n",
        "            predictions = x\n",
        "            count_predictor += 1\n",
        "          else:\n",
        "            predictions = torch.cat((predictions, x), 1)\n",
        "\n",
        "      cache_output[i] = x\n",
        "      # batch * ... * 85\n",
        "    return predictions\n",
        "\n",
        "  def predict_detection(self, x, classes, anchors):\n",
        "    # x = [batch, C, W, H]\n",
        "    grid_size = x.size(2)\n",
        "    num_object_per_cell = len(anchors)\n",
        "    detected_obj_vec_size = 5 + classes\n",
        "\n",
        "    #  finally ==> [btz, 13 * 13 * 3, 85]\n",
        "\n",
        "    # 4d --> 3d\n",
        "    result = x.view(x.size(0), detected_obj_vec_size * num_object_per_cell,\n",
        "           grid_size * grid_size)\n",
        "    # 255 * (13 * 13)  ---> (13* 13) * 255\n",
        "    result = result.transpose(1, 2).contiguous()\n",
        "    # (13* 13) * 255 ---> (13 * 13 * 3) * 85\n",
        "    result = result.view(x.size(0), grid_size * grid_size * num_object_per_cell,\n",
        "                 detected_obj_vec_size)\n",
        "\n",
        "    c_y, c_x = torch.meshgrid(torch.arange(grid_size), torch.arange(grid_size), indexing=\"ij\")\n",
        "    c_x, c_y = c_x.reshape(-1, 1).to(self.device), c_y.reshape(-1, 1).to(self.device)\n",
        "    coordinate_offset = torch.cat((c_x, c_y), 1).repeat(1, 3).view(-1, 2).unsqueeze(0)\n",
        "\n",
        "\n",
        "    # x, y cordinate\n",
        "    result[..., 0:2] = F.sigmoid(result[..., 0:2]) + coordinate_offset\n",
        "\n",
        "    # w, h  b_w = exp(t_w) * p_w\n",
        "    anchors = anchors.repeat(grid_size * grid_size, 1).unsqueeze(0)\n",
        "    result[..., 2:4] = torch.exp(result[..., 2:4]) * anchors\n",
        "\n",
        "    # objectness score\n",
        "    result[..., 4:5] = torch.sigmoid(result[..., 4:5])\n",
        "\n",
        "    # prob per class!\n",
        "    result[..., 5:detected_obj_vec_size] = torch.sigmoid(result[..., 5:detected_obj_vec_size])\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "rk8B6T26HJwP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anchors = torch.tensor([[116.,  90.],\n",
        "        [156., 198.],\n",
        "        [373., 326.]])\n",
        "anchors.repeat(3*3, 1).unsqueeze(0)"
      ],
      "metadata": {
        "id": "mGw81ZXihjWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = YoloV3Net(config, device=\"cpu\")\n",
        "x = torch.randn(8, 3, 416, 416)\n",
        "prediction = model(x)"
      ],
      "metadata": {
        "id": "JlWE5rzLrDMF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "10647 / (3 * (13 * 13 + 26 * 26 + 52 * 52))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWnGry75r0Di",
        "outputId": "90bf84fe-c2be-45df-9e75-3652e0265599"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction[..., 5:].size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3KA2mVOv8qJ",
        "outputId": "8aa554d9-2968-401e-daf2-31d25546d5fb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 10647, 80])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction[..., 4] < threshold\n",
        "# prediction[..., 5:]"
      ],
      "metadata": {
        "id": "qsVqZvDns8oP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: non-max supression!\n",
        "#def iou(box_1, box_2): ---> return iou"
      ],
      "metadata": {
        "id": "i-L2-JL1sof_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "del model\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "RWUiAk0RgXw2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}