{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "w6YucXZRMHoK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
        "!unzip -q spa-eng.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8IpkiI6Mbpn",
        "outputId": "7043460c-f842-4c30-8a83-7c3a3d4f32cb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-05 07:49:22--  http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.216.207, 108.177.12.207, 108.177.13.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.216.207|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2638744 (2.5M) [application/zip]\n",
            "Saving to: ‘spa-eng.zip.1’\n",
            "\n",
            "\rspa-eng.zip.1         0%[                    ]       0  --.-KB/s               \rspa-eng.zip.1       100%[===================>]   2.52M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-04-05 07:49:22 (159 MB/s) - ‘spa-eng.zip.1’ saved [2638744/2638744]\n",
            "\n",
            "replace spa-eng/_about.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n",
            "replace spa-eng/spa.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_file = \"spa-eng/spa.txt\"\n",
        "with open(text_file) as f:\n",
        "  lines = f.read().split(\"\\n\")[:-1]\n",
        "\n",
        "data = []\n",
        "source_data = []\n",
        "target_data = []\n",
        "for line in lines:\n",
        "  source, target = line.split('\\t')\n",
        "  source_data.append(source)\n",
        "  target_data.append(target)\n",
        "  data.append((source, target))"
      ],
      "metadata": {
        "id": "2nb5r67nMmQI"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YoHBkt2PM8u",
        "outputId": "09958b0e-431f-4046-bec4-ab4d527e6bb6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo.',\n",
              " '[start] Si quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un músico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado. [end]')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random.shuffle(data)\n",
        "num_val_samples = int(0.15 * len(data))\n",
        "num_train_samples = len(data) - 2 * num_val_samples\n",
        "\n",
        "train_pairs = data[:num_train_samples]\n",
        "val_pairs = data[num_train_samples:num_train_samples + num_val_samples]\n",
        "test_pairs = data[num_train_samples + num_val_samples:]"
      ],
      "metadata": {
        "id": "rJLnVibfPVEz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counter = Counter({\"gholam\": 2})\n",
        "counter[\"gholama\"]+=1\n",
        "# counter.update(\"y\")\n",
        "counter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0g_f2wSdLnL",
        "outputId": "43f8b326-91c4-43da-9d03-a8e4284764b3"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'gholam': 2, 'gholama': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import string\n",
        "from tqdm import tqdm\n",
        "\n",
        "strip_chars = string.punctuation + \"¿\"\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "\n",
        "class TextVectorizer:\n",
        "\n",
        "  def __init__(self, sequence_length, vocab_size, target=False):\n",
        "    self.target = target\n",
        "    self.sequence_length = sequence_length\n",
        "    self.vocab_size = vocab_size\n",
        "    self.vocab_counter = Counter()\n",
        "    self.stoi = {\"[pad]\": 0, \"[start]\": 1, \"[end]\": 2, \"[UNK]\": 3}\n",
        "    self.itos = {0: \"[pad]\", 1: \"[start]\", 2: \"[end]\", 3: \"[UNK]\"}\n",
        "\n",
        "  def standardize(self, text):\n",
        "    text = text.lower()\n",
        "    return \"\".join(char for char in text\n",
        "                  if char not in strip_chars)\n",
        "\n",
        "  def tokenize(self, text):\n",
        "    text = self.standardize(text)\n",
        "    return text.split()\n",
        "\n",
        "  def make_most_common(self, dataset):\n",
        "\n",
        "    for text in tqdm(dataset):\n",
        "      tokens = self.tokenize(text)\n",
        "      for token in tokens:\n",
        "        self.vocab_counter[token] += 1\n",
        "\n",
        "    for token, _ in self.vocab_counter.most_common(self.vocab_size):\n",
        "      indx = len(self.stoi)\n",
        "      self.stoi[token] = indx\n",
        "      self.itos[indx] = token\n",
        "\n",
        "  def encode(self, text):\n",
        "    text = self.standardize(text)\n",
        "    tokens = self.tokenize(text)\n",
        "    if self.target:\n",
        "      result = ([self.stoi[\"[start]\"]] + [self.stoi.get(token, 3) for token in tokens]\n",
        "            + [self.stoi[\"[end]\"]])\n",
        "    else:\n",
        "      result = [self.stoi.get(token, 3) for token in tokens]\n",
        "\n",
        "    if len(result) <= self.sequence_length:\n",
        "        pad_size = self.sequence_length - len(result)\n",
        "        result += [self.stoi.get(\"[pad]\")] * (pad_size)\n",
        "    else:\n",
        "      #truncate!\n",
        "      result = result[:self.sequence_length]\n",
        "\n",
        "    return result\n",
        "\n",
        "  def decode(self, int_sequence):\n",
        "    return \" \".join(self.itos.get(i, \"[UNK]\") for i in int_sequence)"
      ],
      "metadata": {
        "id": "3P3Je3FeQdgE"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "\n",
        "source_vectorizer = TextVectorizer(sequence_length, vocab_size)\n",
        "target_vectorizer = TextVectorizer(sequence_length + 1, vocab_size, target=True)"
      ],
      "metadata": {
        "id": "rYJcjnLfUFTP"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_vectorizer.make_most_common(source_data)\n",
        "target_vectorizer.make_most_common(target_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIiFXjacgsIE",
        "outputId": "5c65e4d7-c20e-4874-bda5-e57b4b3baa02"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118964/118964 [00:01<00:00, 103539.94it/s]\n",
            "100%|██████████| 118964/118964 [00:00<00:00, 123404.26it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_ = source_vectorizer.encode('If you want to sound')\n",
        "source_vectorizer.decode(encoded_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MsmUNp4niGjR",
        "outputId": "19fcbe55-de40-480b-a3aa-9c95bf808510"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'if you want to sound [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eng, spa = train_pairs[1]\n",
        "source_vectorizer.encode(eng)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5FVsY8TuB-Q",
        "outputId": "c0d7dc12-86db-427f-e016-2ae5dc3e22c2"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[15, 10, 9, 149, 422, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EngSpaDataset(Dataset):\n",
        "  def __init__(self, data, source_vectorizer, target_vectorizer):\n",
        "    self.data = data\n",
        "    self.source_vectorizer = source_vectorizer\n",
        "    self.target_vectorizer = target_vectorizer\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    eng, spa = self.data[idx]\n",
        "    eng = self.source_vectorizer.encode(eng)\n",
        "    spa = self.target_vectorizer.encode(spa)\n",
        "    return ({\n",
        "          \"english\": torch.tensor(eng),\n",
        "          \"spanish\": torch.tensor(spa[:-1]),\n",
        "          }, torch.tensor(spa[1:]))"
      ],
      "metadata": {
        "id": "z8vv0B9WqgTa"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = EngSpaDataset(train_pairs, source_vectorizer, target_vectorizer)\n",
        "val_ds = EngSpaDataset(val_pairs, source_vectorizer, target_vectorizer)\n",
        "test_ds = EngSpaDataset(test_pairs, source_vectorizer, target_vectorizer)"
      ],
      "metadata": {
        "id": "P8nRx0NXsq5L"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "val_dl = DataLoader(val_ds, batch_size=batch_size)\n",
        "test_dl = DataLoader(test_ds, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "d512sQbstCm5"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data, target in train_dl:\n",
        "  print(data)\n",
        "  print(target.size())\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeyoIjW6tmBt",
        "outputId": "8f048b23-4759-4b46-8fd2-30301fe17140"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'english': tensor([[ 18,   7, 970,  ...,   0,   0,   0],\n",
            "        [ 82, 285, 379,  ...,   0,   0,   0],\n",
            "        [ 68,   7, 491,  ...,   0,   0,   0],\n",
            "        ...,\n",
            "        [  4, 469,  13,  ...,   0,   0,   0],\n",
            "        [ 15,  95, 865,  ...,   0,   0,   0],\n",
            "        [110,  10, 196,  ...,   0,   0,   0]]), 'spanish': tensor([[  1,   1, 302,  ...,   0,   0,   0],\n",
            "        [  1,   1,  85,  ...,   0,   0,   0],\n",
            "        [  1,   1,  48,  ...,   0,   0,   0],\n",
            "        ...,\n",
            "        [  1,   1,   9,  ...,   0,   0,   0],\n",
            "        [  1,   1,  79,  ...,   0,   0,   0],\n",
            "        [  1,   1,  10,  ...,   0,   0,   0]])}\n",
            "torch.Size([64, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Cz2Ysm9u-tQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}