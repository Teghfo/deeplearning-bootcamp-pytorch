{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwXCj3AFKGrE"
      },
      "source": [
        "\n",
        "\n",
        "**AutoEncoder**\n",
        "\n",
        "Autoencoders are artificial neural networks capable of learning dense representations of the input data, called latent representations or codings, without any supervision\". This Neural Network architecture is divided into the encoder structure, the decoder structure, and the latent space, also known as the “bottleneck”."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-55DayjwK3Sg"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-5RtTh-LSqk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lahPeWXtMaES"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('font', size=14)\n",
        "plt.rc('axes', labelsize=14, titlesize=14)\n",
        "plt.rc('legend', fontsize=14)\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdz0e4_rJGQ7",
        "outputId": "228c01fb-3782-4f14-b793-0ab66f19dd1e"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"No GPU was detected. Neural nets can be very slow without a GPU.\")\n",
        "    if \"google.colab\" in sys.modules:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware \"\n",
        "              \"accelerator.\")\n",
        "    device = \"cpu\"\n",
        "else:\n",
        "    device = \"cuda\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CApl8lBkLfaM",
        "outputId": "51fad878-f80e-4203-e729-afc5da3cdb78"
      },
      "outputs": [],
      "source": [
        "tensor_transform = transforms.ToTensor()\n",
        "\n",
        "train_ds = datasets.MNIST(root = \"./data\",\n",
        "\t\t\t\t\t\ttrain = True,\n",
        "\t\t\t\t\t\tdownload = True,\n",
        "\t\t\t\t\t\ttransform = tensor_transform)\n",
        "\n",
        "train_dl = torch.utils.data.DataLoader(dataset = train_ds,\n",
        "\t\t\t\t\t\t\t\t\tbatch_size = 32,\n",
        "\t\t\t\t\t\t\t\t\tshuffle = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5MJ15jT7bWK"
      },
      "source": [
        "#Stacked Autoencoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbHTwCQq76w6"
      },
      "outputs": [],
      "source": [
        "stacked_encoder = nn.Sequential(\n",
        "                nn.Linear(28 * 28, 128),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(128, 64),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(64, 36),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(36, 18),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(18, 9)\n",
        "            )\n",
        "\n",
        "stacked_decoder = nn.Sequential(\n",
        "                nn.Linear(9, 18),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(18, 36),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(36, 64),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(64, 128),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(128, 28 * 28),\n",
        "                nn.Sigmoid()\n",
        "            )\n",
        "\n",
        "stacked_ae = nn.Sequential(\n",
        "    stacked_encoder,\n",
        "    stacked_decoder\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ut6qYlJe8wM6",
        "outputId": "bce7c053-4484-4503-cb87-738551822b12"
      },
      "outputs": [],
      "source": [
        "stacked_ae.to(device)\n",
        "stacked_ae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDyuPodV84M0"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(stacked_ae.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eI_LvuEO9eUp",
        "outputId": "8d7438bd-abb9-4314-ad37-f8b314d17c59"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "epochs = 20\n",
        "\n",
        "outputs = []\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    train_loss = 0.0\n",
        "    for (image, _) in tqdm(train_dl):\n",
        "\n",
        "        # Reshaping the image to (-1, 784)\n",
        "        image = image.reshape(-1, 28*28)\n",
        "        image = image.to(device)\n",
        "        reconstructed = stacked_ae(image)\n",
        "        loss = criterion(reconstructed, image)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        outputs.append((epochs, image, reconstructed))\n",
        "    print(f\"Epoch {epoch+1}/{epochs}: train loss: {train_loss/len(train_dl)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mtsm7D35974A"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "@torch.no_grad()\n",
        "def plot_reconstructions(model, images, n_images=5):\n",
        "    reconstructions = model(images[:n_images])\n",
        "    images = images.to(\"cpu\").reshape(-1, 28, 28)\n",
        "    reconstructions = reconstructions.to(\"cpu\").reshape(-1, 28, 28)\n",
        "    fig = plt.figure(figsize=(n_images * 1.5, 3))\n",
        "    for image_index in range(n_images):\n",
        "        plt.subplot(2, n_images, 1 + image_index)\n",
        "        plt.imshow(images[image_index], cmap=\"binary\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.subplot(2, n_images, 1 + n_images + image_index)\n",
        "        plt.imshow(reconstructions[image_index], cmap=\"binary\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "plot_reconstructions(stacked_ae, image, 10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Gzk1bbePZ__"
      },
      "source": [
        "#Convolutional AutoEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hCQ5pe0PZsl"
      },
      "outputs": [],
      "source": [
        "conv_encoder = nn.Sequential(\n",
        "    nn.Conv2d(1, 16, 3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2, 2),  # output = 14 * 14 * 16\n",
        "    nn.Conv2d(16, 32, 3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2, 2),\n",
        "    nn.Conv2d(32, 64, 3, padding=1),  # output = 7 * 7 * 32\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2, 2),  # output = 3 * 3 * 64\n",
        "    nn.AdaptiveAvgPool2d(1),\n",
        "    nn.Flatten()\n",
        ")\n",
        "\n",
        "conv_decoder = nn.Sequential(\n",
        "    nn.Linear(64, 3 * 3 * 64),\n",
        "    nn.Unflatten(1, (64, 3, 3)),\n",
        "    nn.ConvTranspose2d(64, 32, 3, stride=2), # output = 32 * 7 * 7\n",
        "    nn.ReLU(),\n",
        "    nn.ConvTranspose2d(32, 16, 3, padding=1, stride=2), # outout = 16 * 14 * 14\n",
        "    nn.ReLU(),\n",
        "    nn.ConvTranspose2d(16, 1, 3, stride=2, output_padding=1),  # output =  1 * 28 * 28\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "conv_ae = nn.Sequential(\n",
        "    conv_encoder,\n",
        "    conv_decoder\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyQCgUIMXvpN"
      },
      "outputs": [],
      "source": [
        "conv_ae = conv_ae.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iM6W4bd_XIsN"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "epochs = 20\n",
        "\n",
        "outputs = []\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    train_loss = 0.0\n",
        "    for (image, _) in tqdm(train_dl):\n",
        "\n",
        "        # Reshaping the image to (-1, 784)\n",
        "        image = image.to(device)\n",
        "        reconstructed = conv_ae(image)\n",
        "        loss = criterion(reconstructed.view(-1, 28 * 28), image.view(-1, 28 * 28))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        outputs.append((epochs, image, reconstructed))\n",
        "    print(f\"Epoch {epoch+1}/{epochs}: train loss: {train_loss/len(train_dl)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKKTjtqydOXR"
      },
      "source": [
        "# VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8Zqv6-nZylj"
      },
      "outputs": [],
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, input_size, latent_size, device=\"cuda\"):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(input_size, 300),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(300, 100),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.mean_layer = nn.Linear(100, latent_size)\n",
        "        self.logvar_layer = nn.Linear(100, latent_size)\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_size, 100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100, 300),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(300, input_size),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        enc_out = self.encoder(x)\n",
        "        mean, logvar = self.mean_layer(enc_out), self.logvar_layer(enc_out)\n",
        "        eps = torch.randn_like(mean).to(self.device)\n",
        "        z = eps * logvar + mean\n",
        "        return self.decoder(z), mean, logvar\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzqK1oDEktzX"
      },
      "outputs": [],
      "source": [
        "class VAELoss(nn.Module):\n",
        "    def forward(self, reconstruction, x, mean, logvar):\n",
        "        loss_reconstruction = nn.MSELoss()(reconstruction, x)\n",
        "        loss_kld = -0.5 * torch.sum(1 + logvar - logvar.exp() - mean.pow(2))\n",
        "        return loss_reconstruction + loss_kld"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qh3Ls3XwmuS1"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "\n",
        "model = VAE(784, 50, device=device).to(device)\n",
        "criterion = VAELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6OHDMxcnNRM",
        "outputId": "f6562f0f-3ae1-46fb-e82f-00b89caf0881"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "epochs = 20\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    train_loss = 0.0\n",
        "    for (image, _) in tqdm(train_dl):\n",
        "\n",
        "        # Reshaping the image to (-1, 784)\n",
        "        image = image.to(device)\n",
        "        reconstructed, mean, logvar = model(image)\n",
        "        loss = criterion(reconstructed, image.view(-1, 784), mean, logvar)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{epochs}: train loss: {train_loss/len(train_dl)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "6Gzk1bbePZ__"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
